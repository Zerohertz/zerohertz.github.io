---
title: 'Apache Airflow: Continuous Training'
date: 2023-08-27 22:41:03
categories:
- 4. MLOps
tags:
- Airflow
- Python
- scikit-learn
- Docker
- CI/CD
- Kubernetes
- Home Server
---
# Introduction

Data ê¸°ë°˜ ì˜ì‚¬ê²°ì •ì˜ ì‹œëŒ€ì— ì§„ì…í•˜ë©°, machine learning modelì€ ë‹¤ì–‘í•œ ë¹„ì¦ˆë‹ˆìŠ¤ applicationì˜ ì¤‘ì‹¬ ìš”ì†Œë¡œ ë¶€ìƒí•˜ê³  ìˆë‹¤.
ê·¸ë ‡ì§€ë§Œ ë‹¤ë¥¸ ê¸°ìˆ ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, modelì˜ íš¨ê³¼ì™€ ì‹ ë¢°ë„ëŠ” ì£¼ë¡œ ì–´ë–¤ dataë¡œ í›ˆë ¨ë°›ì•˜ëŠ”ê°€ì— í° ì˜í–¥ì„ ë°›ëŠ”ë‹¤.
ì´ì— ë”°ë¼ data shift ë¬¸ì œë¥¼ í•„ì—°ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼í•œë‹¤.
Data shiftëŠ” íŠ¹ì • modelì´ í›ˆë ¨ì„ ë°›ì€ dataì˜ ë¶„í¬ì™€ ì‹¤ì œ ì„¸ê³„ì—ì„œ ì ‘í•˜ëŠ” dataì˜ ë¶„í¬ ì‚¬ì´ì— ì°¨ì´ê°€ ìƒê¸¸ ë•Œ ë‚˜íƒ€ë‚œë‹¤.
ì´ë¡œ ì¸í•´ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ í¬ê²Œ ì €í•˜ë˜ê±°ë‚˜ ì˜ˆì¸¡ì´ ì™œê³¡ë  ìˆ˜ ìˆë‹¤.
ì‹¤ì œ ì„¸ê³„ì˜ ë°ì´í„°ëŠ” ê³„ì ˆ ë³€í™”, ì‹œì¥ ë™í–¥ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ìš”ì¸ë“¤ë¡œ ì§€ì†ì ìœ¼ë¡œ ë³€í™”í•˜ë¯€ë¡œ, ë‹¨ìˆœíˆ ëª¨ë¸ì„ ìƒì„±í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ê·¸ ë³€í™”ì— ëŒ€ì‘í•˜ê¸° ì–´ë µë‹¤.
ì´ ë•Œë¬¸ì— modelì´ ì§€ì†ì ìœ¼ë¡œ ë°ì´í„°ì˜ ë³€í™”ì— ì ì‘í•˜ë©´ì„œ ê´€ë ¨ì„±ì„ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•˜ëŠ” mechanismì´ í•„ìš”í•˜ë‹¤ëŠ” ì¸ì‹ì´ ìƒê²¼ê³ , continuous learningì´ ì£¼ëª©ë°›ê²Œ ë˜ì—ˆë‹¤.
Continuous learningì€ ìµœê·¼ì˜ ë°ì´í„° ë³€í™”ë¥¼ í¬ì°©í•˜ê³  ì ì‘í•˜ë©´ì„œ modelì„ ì£¼ê¸°ì ìœ¼ë¡œ ê°±ì‹ í•˜ëŠ” ì²´ê³„ë‹¤.
ê·¸ëŸ¬ë‚˜ ì´ëŸ° ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì€ ë³µì¡í•˜ë©° ì—¬ëŸ¬ ìš”ì†Œë¥¼ ê³ ë ¤í•´ì•¼ í•œë‹¤.
ë”°ë¼ì„œ ì´ë²ˆ ê¸€ì—ì„œëŠ”, data shiftê°€ ì‹œê°„ì— ë”°ë¼ ë°œìƒí•˜ëŠ” ì˜ˆì œ ë°ì´í„°ë¥¼ ìƒì„±í•´ ë³¼ ê²ƒì´ë©°, ê·¸ dataë¥¼ ê¸°ë°˜ìœ¼ë¡œ Apache Airflowë¥¼ ì´ìš©í•´ ì•„ë˜ì™€ ê°™ì´ continuous trainingí•˜ëŠ” DAGë¥¼ ë§Œë“¤ì–´ continuous learningì— ëŒ€í•œ ì´í•´ë¥¼ ì¡°ê¸ˆì´ë‚˜ ì–»ì–´ë³´ë ¤ê³ í•œë‹¤.

![results](/images/airflow-ct/results.gif)

<!-- More -->

---

# Data Shift

ë¨¼ì € ì‹œê°„ì— ë”°ë¥¸ ë°ì´í„°ë¥¼ ì…ë ¥í•  DB (PostgreSQL)ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ ì•„ë˜ manifestë¥¼ ì‹¤í–‰í•œë‹¤.
`Service`ì™€ `Deployment`ëŠ” `kubectl apply -f postgresql.yaml`ì„ í†µí•´ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤.

```yaml postgresql.yaml
apiVersion: v1
kind: Service
metadata:
  name: ${POSTGRESQL_NAME}
  namespace: airflow
  labels:
    app: ${POSTGRESQL_LABEL}
spec:
  ports:
    - port: 5432
  selector:
    app: zerohertz-db
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ${POSTGRESQL_NAME}
  namespace: airflow
spec:
  replicas: 1
  selector:
    matchLabels:
    app: ${POSTGRESQL_LABEL}
  template:
    metadata:
      labels:
        app: ${POSTGRESQL_LABEL}
    spec:
      containers:
        - name: ${POSTGRESQL_NAME}
          image: postgres:latest
          env:
            - name: POSTGRES_DB
              value: ${DB}
            - name: POSTGRES_USER
              value: ${USER}
            - name: POSTGRES_PASSWORD
              value: ${PASSWORD}
          ports:
            - containerPort: 5432
```

Podê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©´ ì•„ë˜ì™€ ê°™ì´ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

```sql
DB=# \du
                                   List of roles
 Role name |                         Attributes                         | Member of 
-----------+------------------------------------------------------------+-----------
 Zerohertz | Superuser, Create role, Create DB, Replication, Bypass RLS | {}

DB=# \l
                                                  List of databases
   Name    |   Owner   | Encoding |  Collate   |   Ctype    | ICU Locale | Locale Provider |    Access privileges    
-----------+-----------+----------+------------+------------+------------+-----------------+-------------------------
 DB        | Zerohertz | UTF8     | en_US.utf8 | en_US.utf8 |            | libc            | 
 postgres  | Zerohertz | UTF8     | en_US.utf8 | en_US.utf8 |            | libc            | 
 template0 | Zerohertz | UTF8     | en_US.utf8 | en_US.utf8 |            | libc            | =c/Zerohertz           +
           |           |          |            |            |            |                 | Zerohertz=CTc/Zerohertz
 template1 | Zerohertz | UTF8     | en_US.utf8 | en_US.utf8 |            | libc            | =c/Zerohertz           +
           |           |          |            |            |            |                 | Zerohertz=CTc/Zerohertz
(4 rows)
```

ë¨¸ë¦¬ ì†ì— ê¹Šì´ ì ìê³  ìˆëŠ” ê³ ë“±í•™êµ ë•Œ ë°°ì› ë˜ ìˆ˜í•™ë“¤ì„ êº¼ë‚´ì–´ ì•„ë˜ ì½”ë“œë¥¼ êµ¬í˜„í–ˆë‹¤.
ì£¼ì–´ì§„ classì˜ ìˆ˜ì™€ ì‹œê°„ì— ë”°ë¼ ë³€í™”í•˜ê³  ì›ì ê³¼ì˜ ê±°ë¦¬ê°€ `ENV.RADIUS`ì´ë©° ë¶„ì‚°ì´ 1ì¸ ì •ê·œë¶„í¬ ë°ì´í„°ë¥¼ ë§Œë“¤ì—ˆë‹¤.
ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ì„œ í‰ê·  (`mean_x`, `mean_y`)ì´ ì›ì„ ê·¸ë¦¬ë„ë¡ ê°œë°œí–ˆë‹¤.
ì´ë ‡ê²Œ ìƒì„±ëœ dataëŠ” `PostgresOperator`ë¡œ queryë¥¼ ë³´ë‚´ dataë¥¼ ì ì¬í•  ìˆ˜ ìˆê²Œ í–ˆë‹¤.

```python CreateData.py
import math

import airflow
import numpy as np
from airflow.decorators import dag
from airflow.operators.python_operator import PythonOperator
from airflow.providers.postgres.operators.postgres import PostgresOperator
from dateutil.parser import parse
from lib import Environment

ENV = Environment("CT")


def _mean(time, class_name):
    idx = ENV.CLASSES.index(class_name)
    time = time / 24 * 2 * math.pi
    mean_x = math.sqrt(ENV.RADIUS) * math.cos(
        time + 2 * math.pi * idx / len(ENV.CLASSES)
    )
    mean_y = math.sqrt(ENV.RADIUS) * math.sin(
        time + 2 * math.pi * idx / len(ENV.CLASSES)
    )
    return mean_x, mean_y


def _generate_queries(class_name, num_entries, ts):
    queries = []
    mean_x, mean_y = _mean(int(ts[11:13]), class_name)
    ts = parse(ts)
    for _ in range(num_entries):
        x = np.random.normal(mean_x, 1)
        y = np.random.normal(mean_y, 1)
        queries.append(
            f"INSERT INTO CONTINUOUS_TRAINING (time, x, y, class) VALUES ('{ts.strftime('%Y-%m-%d %H:%M:%S%z')}', {x}, {y}, '{class_name}');"
        )
    return "\n".join(queries)


def _merge_queries(ti):
    queries = []
    for c in ENV.CLASSES:
        queries.append(ti.xcom_pull(task_ids=f"generate_data_{c}"))
    return "\n".join(queries)


@dag(
    dag_id="Create-Data",
    start_date=airflow.utils.dates.days_ago(2),
    end_date=airflow.utils.dates.days_ago(1),
    schedule_interval="@hourly",
    max_active_runs=12,
    catchup=True,
    tags=["MLOps", "Data Engineering"],
)
def create_data():
    create_table = PostgresOperator(
        task_id="create_table",
        postgres_conn_id=ENV.DB,
        sql="""
        CREATE TABLE IF NOT EXISTS
        CONTINUOUS_TRAINING (
            time TIMESTAMP NOT NULL,
            x FLOAT NOT NULL,
            y FLOAT NOT NULL,
            class TEXT NOT NULL
        );
        """,
    )

    generate_queries = []

    for c in ENV.CLASSES:
        generate_query = PythonOperator(
            task_id=f"generate_data_{c}",
            python_callable=_generate_queries,
            op_args=[c, ENV.NO_DATA],
            do_xcom_push=True,
        )
        generate_queries.append(generate_query)

    merge_queries = PythonOperator(
        task_id="merge_queries", python_callable=_merge_queries, do_xcom_push=True,
    )

    push_data = PostgresOperator(
        task_id="push_data",
        postgres_conn_id=ENV.DB,
        sql="{{ ti.xcom_pull(task_ids='merge_queries', key='return_value') }}",
    )

    create_table >> generate_queries >> merge_queries >> push_data


DAG = create_data()
```

ì‹œê°„ì— ë”°ë¥¸ í‰ê·  ê°’ë“¤ì„ ì•Œì•„ë³´ê¸° ìœ„í•´ ì•„ë˜ queryë¥¼ ì‘ì„±í–ˆë‹¤.
ì‹œê°„ê³¼ classì— ë”°ë¥¸ ëŒ€ëµì ì¸ ê°’ì„ ë³´ë©´ ì¡°ê¸ˆì”© íšŒì „í•˜ê³  ìˆìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.

```sql
DB=# SELECT 
time,
class,
AVG(x) AS avg_x,
AVG(y) AS avg_y
FROM 
    continuous_training
WHERE 
    class IN ('A', 'B', 'C') 
GROUP BY 
    time, class
ORDER BY 
    time, class;
        time         | class |         avg_x         |         avg_y         
---------------------+-------+-----------------------+-----------------------
 2023-08-26 00:00:00 | A     |    2.4045409487416998 |  0.040922815013869365
 2023-08-26 00:00:00 | B     |   -1.1737959659258457 |    2.1460601636034657
 2023-08-26 00:00:00 | C     |   -1.2033114946199557 |   -2.0674824541958245
 2023-08-26 01:00:00 | A     |    2.2658467036147827 |    0.5747269069953029
 2023-08-26 01:00:00 | B     |   -1.8425758017968537 |    1.8098944512019666
 2023-08-26 01:00:00 | C     |   -0.6915502372929186 |    -2.407668482725042
 2023-08-26 02:00:00 | A     |     2.150430855425532 |     1.191560603528595
 2023-08-26 02:00:00 | B     |    -2.082350490108075 |    1.1374431005941859
 2023-08-26 02:00:00 | C     | -0.011051726332470002 |   -2.4709247754120476
 2023-08-26 03:00:00 | A     |    1.6417773209790472 |     1.720475275302636
 2023-08-26 03:00:00 | B     |    -2.302885070406296 |    0.6431434361363254
 2023-08-26 03:00:00 | C     |    0.7193753880170582 |   -2.3782277040762754
 2023-08-26 04:00:00 | A     |     1.087256799646457 |    2.2591619532786407
 2023-08-26 04:00:00 | B     |   -2.3960202086984657 |  0.019288817697385604
 2023-08-26 04:00:00 | C     |    1.2260408746440097 |    -2.093929943264823
...
```

---

# Continuous Training

í•™ìŠµì„ í•˜ê³  ì‹œê°í™”í•˜ê¸° ìœ„í•´ì„œëŠ” `scikit-learn`,`matplotlib`ê³¼ ê°™ì€ ë‹¤ì–‘í•œ libraryê°€ í•„ìš”í•˜ë‹ˆ `KubernetesPodOperator`ë¥¼ ì‚¬ìš©í•œë‹¤.
ë˜í•œ ìœ„ì—ì„œ ì ì¬í•œ dataë“¤ì„ ì‹œê°„ì— ë”°ë¼ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´ `PostgresOperator`ë¥¼ ì‚¬ìš©í•˜ë ¤ í–ˆìœ¼ë‚˜, dataì˜ ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì•„ë˜ì™€ ê°™ì€ í™œìš©ì´ ë¶ˆê°€ëŠ¥í•¨ì„ í™•ì¸í–ˆë‹¤.

```python
get_data = KubernetesPodOperator(
    ...
    arguments=[
        "{{ task_instance.xcom_pull(task_ids='fetch_recent_data', key='return_value') }}"
    ],
)
```

ë”°ë¼ì„œ `KubernetesPodOperator`ì˜ Docker imageì—ì„œ DBì˜ dataë¥¼ ì¶”ì¶œí•˜ê³  í•™ìŠµí•  ìˆ˜ ìˆê²Œ ì•„ë˜ DAGë¥¼ ê°œë°œí–ˆë‹¤.
`generate_queries` taskì—ì„œ logical timeì˜ 2ì‹œê°„ ì „ ë¶€í„° logical timeê¹Œì§€ì˜ dataë¥¼ ê°€ì ¸ì˜¤ëŠ” queryë¥¼ `KubernetesPodOperator`ì˜ í™˜ê²½ ë³€ìˆ˜ë¡œ ì…ë ¥ë°›ì„ ìˆ˜ ìˆê²Œ ì‘ì„±í•œë‹¤.

```python ContinuousTraining.py
import airflow
from airflow.decorators import dag
from airflow.operators.python_operator import PythonOperator
from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import (
    KubernetesPodOperator,
)
from dateutil.parser import parse
from lib import Environment, _send_discord_message

ENV = Environment("CT")


def _generate_queries(ts):
    ts = parse(ts)
    return f"""
            SELECT * FROM continuous_training
            WHERE time >= TIMESTAMP '{ts.strftime('%Y-%m-%d %H:%M:%S%z')}' - INTERVAL '2 hours'
            AND time <= TIMESTAMP '{ts.strftime('%Y-%m-%d %H:%M:%S%z')}';
            """


@dag(
    dag_id="Continuous-Training",
    start_date=airflow.utils.dates.days_ago(2),
    end_date=airflow.utils.dates.days_ago(1),
    schedule_interval="@hourly",
    max_active_runs=1,
    catchup=True,
    tags=["MLOps", "Continuous Training"],
)
def continuous_training():
    generate_queries = PythonOperator(
        task_id="generate_queries", python_callable=_generate_queries
    )

    send_training_log = PythonOperator(
        task_id="send_training_log",
        python_callable=_send_discord_message,
        op_kwargs={
            "webhook_url": ENV.WEBHOOK,
            "content": ":computer: [{{ ts }}]: TRAINING START!",
        },
    )

    training = KubernetesPodOperator(
        task_id="training",
        name="training",
        image="zerohertzkr/airflow-continuous-training",
        env_vars={
            "WEBHOOK": ENV.WEBHOOK,
            "CLASSES": str(ENV.CLASSES),
            "TIME": "{{ ts }}",
            "QUERY": "{{ ti.xcom_pull(task_ids='generate_queries', key='return_value') }}",
            "user": ENV.DB_USER,
            "password": ENV.DB_PASSWORD,
            "host": ENV.DB,
            "port": ENV.DB_PORT,
            "database": ENV.DB_DATABASE,
        },
    )

    generate_queries >> [send_training_log, training]


DAG = continuous_training()
```

ìœ„ì—ì„œ ì •ì˜í•œ Docker image ë‚´ì˜ í™˜ê²½ ë³€ìˆ˜ë“¤ì„ ê°€ì ¸ì˜¤ê³  ê·¸ ê°’ë“¤ì„ í†µí•´ DBì— ì—°ê²°í•˜ê³  queryë¡œ DBì—ì„œ ì›í•˜ëŠ” dataë¥¼ ì¶”ì¶œí•œë‹¤.
ê·¸ë¦¬ê³  í•™ìŠµí•œ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ê³  Discord webhookìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•œë‹¤.
ìƒì„±í•œ dataì— ëŒ€í•´ ê°€ì¥ ì§ê´€ì ìœ¼ë¡œ ì‹œê°í™”í•  ìˆ˜ ìˆëŠ” Decision Treeë¥¼ ì‚¬ìš©í•  modelë¡œ ì±„íƒí–ˆë‹¤.

```python airflow-continuous-training/main.py
import os

import matplotlib.pyplot as plt
import numpy as np
import psycopg2
import requests
from sklearn.tree import DecisionTreeClassifier

WEBHOOK = os.environ.get("WEBHOOK")
CLASSES = eval(os.environ.get("CLASSES"))
TIME = os.environ.get("TIME")
QUERY = os.environ.get("QUERY")
user = os.environ.get("user")
password = os.environ.get("password")
host = os.environ.get("host")
port = os.environ.get("port")
database = os.environ.get("database")


def execute_query(query):
    with psycopg2.connect(
        user=user, password=password, host=host, port=port, database=database
    ) as connection:
        with connection.cursor() as cursor:
            cursor.execute(query)
            records = cursor.fetchall()
    return records


def main():
    data = execute_query(QUERY)
    X = np.array([[item[1], item[2]] for item in data])
    y = np.array([CLASSES.index(item[3]) for item in data])

    clf = DecisionTreeClassifier()
    clf.fit(X, y)

    plt.figure(figsize=(10, 10))
    ax = plt.gca()

    xlim = (-7, 7)
    ylim = (-7, 7)

    xx = np.linspace(xlim[0], xlim[1], 500)
    yy = np.linspace(ylim[0], ylim[1], 500)

    YY, XX = np.meshgrid(yy, xx)
    xy = np.vstack([XX.ravel(), YY.ravel()]).T
    Z = clf.predict(xy)

    n_classes = len(CLASSES)
    colors = plt.cm.jet(np.linspace(0, 1, n_classes))

    ax.contourf(
        XX, YY, Z.reshape(XX.shape), levels=n_classes - 1, colors=colors, alpha=0.5
    )
    scatter = ax.scatter(
        X[:, 0], X[:, 1], c=y, marker="o", edgecolors="k", cmap=plt.cm.jet
    )

    legend_handles = [
        plt.Line2D(
            [0],
            [0],
            marker="o",
            color="w",
            label=f"CLASS {CLASSES[i]}",
            markersize=10,
            markerfacecolor=colors[i],
        )
        for i in range(n_classes)
    ]
    ax.legend(handles=legend_handles, loc="upper right")

    plt.xlim(xlim)
    plt.ylim(ylim)
    plt.title(TIME)
    plt.grid()
    plt.savefig("result.png", bbox_inches="tight")

    with open("result.png", "rb") as f:
        files = {"file": (f"{TIME}.png", f, "image/png")}
        requests.post(WEBHOOK, files=files)


if __name__ == "__main__":
    main()
```

ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

![continuous-training](/images/airflow-ct/continuous-training.gif)

ì‹¤ì œ production í™˜ê²½ì—ì„œëŠ” ë‹¹ì—°íˆ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¶€ì¡±í•¨ ë§ì€ ì½”ë“œì…ë‹ˆë‹¤,,,
ê³ ìˆ˜ ë¶„ë“¤ì˜ ì§€ì ì„ í™˜ì˜í•©ë‹ˆë‹¤,,, ğŸ«¡